{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03. Generate Embeddings\n",
                "\n",
                "## What are Embeddings?\n",
                "Computers don't understand text; they understand numbers. \n",
                "**Embeddings** are lists of numbers (vectors) that represent the *meaning* of a piece of text.\n",
                "\n",
                "For example:\n",
                "- \"Dog\" and \"Puppy\" will have very similar numbers.\n",
                "- \"Dog\" and \"Car\" will have very different numbers.\n",
                "\n",
                "We will use a pre-trained AI model to convert our text chunks into these number lists."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Libraries\n",
                "We use `sentence-transformers`, a great library for creating embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install sentence-transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load Chunked Data\n",
                "We load the `silver_chunks` table from the previous step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.sql(\"USE rag_demo\")\n",
                "df_chunks = spark.table(\"silver_chunks\")\n",
                "display(df_chunks)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Define Embedding Function\n",
                "We will use a model called `all-MiniLM-L6-v2`. It's small, fast, and works well on CPUs (perfect for the Free Edition)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql.functions import pandas_udf, col\n",
                "from pyspark.sql.types import ArrayType, FloatType\n",
                "import pandas as pd\n",
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "# Name of the model we want to download\n",
                "model_name = \"all-MiniLM-L6-v2\"\n",
                "\n",
                "# Define a Pandas UDF to run the model on our data\n",
                "@pandas_udf(ArrayType(FloatType()))\n",
                "def generate_embeddings_udf(text_series: pd.Series) -> pd.Series:\n",
                "    # Load the model inside the function (so it works on worker nodes)\n",
                "    model = SentenceTransformer(model_name)\n",
                "    \n",
                "    # Generate embeddings for the whole batch of text\n",
                "    embeddings = model.encode(text_series.tolist())\n",
                "    \n",
                "    # Return as a Series of lists\n",
                "    return pd.Series(embeddings.tolist())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Compute Embeddings\n",
                "Now we run the function. This might take a minute or two depending on how much data you have."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the UDF to the 'chunk_text' column\n",
                "# repartition(4) helps split the work across available cores\n",
                "df_with_embeddings = df_chunks.repartition(4).withColumn(\n",
                "    \"embedding\", \n",
                "    generate_embeddings_udf(col(\"chunk_text\"))\n",
                ")\n",
                "\n",
                "display(df_with_embeddings)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Save to Gold Table\n",
                "We save the results to `gold_embeddings`. This table now contains both the text and its mathematical representation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_with_embeddings.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_embeddings\")\n",
                "\n",
                "print(\"Success! Embeddings generated and saved to 'gold_embeddings'.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}